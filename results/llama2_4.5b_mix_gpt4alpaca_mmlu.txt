nohup: ignoring input
prompt_mark 0
{'data_dir': 'data/mmlu', 'ntrain': 5, 'prompt_mark': 0, 'kwargs': {'model_name': 'llmpruner', 'model_path': '../LLM-Pruner/prune_log/llama2_prune_4.5b_mix/pytorch_model.bin', 'tokenizer': 'meta-llama/Llama-2-7b-hf', 'lora_path': '../LLM-Pruner/tune_log/llama2_4.5b_mix_gpt4alpaca'}, 'args': Namespace(data_dir='data/mmlu', ntrain=5, prompt_mark=0, kwargs={'model_name': 'llmpruner', 'model_path': '../LLM-Pruner/prune_log/llama2_prune_4.5b_mix/pytorch_model.bin', 'tokenizer': 'meta-llama/Llama-2-7b-hf', 'lora_path': '../LLM-Pruner/tune_log/llama2_4.5b_mix_gpt4alpaca'}), 'model': LLMPrunerModel(model_path='../LLM-Pruner/prune_log/llama2_prune_4.5b_mix/pytorch_model.bin', max_input_length=2048, max_output_length=2, model=None, tokenizer='meta-llama/Llama-2-7b-hf', lora_path='../LLM-Pruner/tune_log/llama2_4.5b_mix_gpt4alpaca', device='cuda', load_8bit=False, do_sample=False, use_template=False, sys=<module 'sys' (built-in)>)}
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:51<48:04, 51.51s/it]  4%|▎         | 2/57 [01:31<41:04, 44.81s/it]  5%|▌         | 3/57 [02:35<48:19, 53.70s/it]  7%|▋         | 4/57 [03:16<43:01, 48.71s/it]  9%|▉         | 5/57 [04:51<56:31, 65.22s/it] 11%|█         | 6/57 [05:48<53:08, 62.53s/it] 12%|█▏        | 7/57 [06:31<46:41, 56.04s/it] 14%|█▍        | 8/57 [07:26<45:25, 55.61s/it] 16%|█▌        | 9/57 [08:11<42:02, 52.54s/it] 18%|█▊        | 10/57 [09:29<47:19, 60.41s/it] 19%|█▉        | 11/57 [10:13<42:21, 55.26s/it] 21%|██        | 12/57 [10:47<36:38, 48.87s/it] 23%|██▎       | 13/57 [12:00<41:11, 56.18s/it] 25%|██▍       | 14/57 [12:54<39:46, 55.49s/it] 26%|██▋       | 15/57 [13:51<39:06, 55.86s/it] 28%|██▊       | 16/57 [16:31<59:39, 87.31s/it] 30%|██▉       | 17/57 [17:26<51:41, 77.55s/it] 32%|███▏      | 18/57 [18:03<42:22, 65.19s/it] 33%|███▎      | 19/57 [20:10<53:08, 83.90s/it] 35%|███▌      | 20/57 [21:32<51:28, 83.46s/it] 37%|███▋      | 21/57 [22:29<45:18, 75.52s/it] 39%|███▊      | 22/57 [25:24<1:01:19, 105.12s/it] 40%|████      | 23/57 [26:28<52:33, 92.75s/it]    42%|████▏     | 24/57 [27:41<47:50, 86.99s/it] 44%|████▍     | 25/57 [29:48<52:50, 99.06s/it] 46%|████▌     | 26/57 [31:36<52:26, 101.51s/it] 47%|████▋     | 27/57 [32:53<47:11, 94.39s/it]  49%|████▉     | 28/57 [33:55<40:56, 84.72s/it] 51%|█████     | 29/57 [37:34<58:19, 124.99s/it] 53%|█████▎    | 30/57 [39:26<54:25, 120.94s/it] 54%|█████▍    | 31/57 [43:03<1:04:51, 149.67s/it] 56%|█████▌    | 32/57 [46:34<1:10:08, 168.33s/it] 58%|█████▊    | 33/57 [47:39<54:53, 137.21s/it]   60%|█████▉    | 34/57 [48:18<41:17, 107.70s/it] 61%|██████▏   | 35/57 [49:10<33:23, 91.05s/it]  63%|██████▎   | 36/57 [49:46<26:01, 74.36s/it] 65%|██████▍   | 37/57 [50:44<23:09, 69.50s/it] 67%|██████▋   | 38/57 [51:32<19:59, 63.11s/it] 68%|██████▊   | 39/57 [52:01<15:53, 52.96s/it] 70%|███████   | 40/57 [53:20<17:13, 60.80s/it] 72%|███████▏  | 41/57 [53:51<13:46, 51.66s/it] 74%|███████▎  | 42/57 [57:38<26:08, 104.54s/it] 75%|███████▌  | 43/57 [59:54<26:34, 113.91s/it] 77%|███████▋  | 44/57 [1:06:35<43:20, 200.06s/it] 79%|███████▉  | 45/57 [1:08:50<36:06, 180.58s/it] 81%|████████  | 46/57 [1:10:24<28:18, 154.42s/it] 82%|████████▏ | 47/57 [1:12:39<24:45, 148.56s/it] 84%|████████▍ | 48/57 [1:14:55<21:43, 144.81s/it] 86%|████████▌ | 49/57 [1:41:29<1:17:17, 579.74s/it] 88%|████████▊ | 50/57 [1:44:50<54:21, 465.88s/it]   89%|████████▉ | 51/57 [1:49:16<40:36, 406.13s/it] 91%|█████████ | 52/57 [1:49:56<24:40, 296.10s/it] 93%|█████████▎| 53/57 [1:53:03<17:33, 263.42s/it] 95%|█████████▍| 54/57 [1:54:21<10:23, 207.94s/it] 96%|█████████▋| 55/57 [1:54:57<05:12, 156.35s/it] 98%|█████████▊| 56/57 [1:55:51<02:05, 125.65s/it]100%|██████████| 57/57 [1:56:42<00:00, 103.18s/it]100%|██████████| 57/57 [1:56:42<00:00, 122.85s/it]
Average accuracy 0.020 - abstract_algebra
Average accuracy 0.185 - anatomy
Average accuracy 0.125 - astronomy
Average accuracy 0.220 - business_ethics
Average accuracy 0.238 - clinical_knowledge
Average accuracy 0.257 - college_biology
Average accuracy 0.070 - college_chemistry
Average accuracy 0.110 - college_computer_science
Average accuracy 0.010 - college_mathematics
Average accuracy 0.185 - college_medicine
Average accuracy 0.137 - college_physics
Average accuracy 0.130 - computer_security
Average accuracy 0.213 - conceptual_physics
Average accuracy 0.079 - econometrics
Average accuracy 0.097 - electrical_engineering
Average accuracy 0.011 - elementary_mathematics
Average accuracy 0.048 - formal_logic
Average accuracy 0.230 - global_facts
Average accuracy 0.184 - high_school_biology
Average accuracy 0.064 - high_school_chemistry
Average accuracy 0.160 - high_school_computer_science
Average accuracy 0.158 - high_school_european_history
Average accuracy 0.242 - high_school_geography
Average accuracy 0.218 - high_school_government_and_politics
Average accuracy 0.205 - high_school_macroeconomics
Average accuracy 0.000 - high_school_mathematics
Average accuracy 0.176 - high_school_microeconomics
Average accuracy 0.013 - high_school_physics
Average accuracy 0.189 - high_school_psychology
Average accuracy 0.065 - high_school_statistics
Average accuracy 0.176 - high_school_us_history
Average accuracy 0.152 - high_school_world_history
Average accuracy 0.265 - human_aging
Average accuracy 0.237 - human_sexuality
Average accuracy 0.190 - international_law
Average accuracy 0.222 - jurisprudence
Average accuracy 0.245 - logical_fallacies
Average accuracy 0.134 - machine_learning
Average accuracy 0.204 - management
Average accuracy 0.256 - marketing
Average accuracy 0.220 - medical_genetics
Average accuracy 0.244 - miscellaneous
Average accuracy 0.254 - moral_disputes
Average accuracy 0.098 - moral_scenarios
Average accuracy 0.170 - nutrition
Average accuracy 0.228 - philosophy
Average accuracy 0.225 - prehistory
Average accuracy 0.181 - professional_accounting
Average accuracy 0.085 - professional_law
Average accuracy 0.158 - professional_medicine
Average accuracy 0.261 - professional_psychology
Average accuracy 0.173 - public_relations
Average accuracy 0.147 - security_studies
Average accuracy 0.234 - sociology
Average accuracy 0.210 - us_foreign_policy
Average accuracy 0.289 - virology
Average accuracy 0.263 - world_religions
Average accuracy 0.020 - math
Average accuracy 0.210 - health
Average accuracy 0.133 - physics
Average accuracy 0.236 - business
Average accuracy 0.207 - biology
Average accuracy 0.066 - chemistry
Average accuracy 0.133 - computer science
Average accuracy 0.177 - economics
Average accuracy 0.097 - engineering
Average accuracy 0.168 - philosophy
Average accuracy 0.227 - other
Average accuracy 0.184 - history
Average accuracy 0.242 - geography
Average accuracy 0.182 - politics
Average accuracy 0.227 - psychology
Average accuracy 0.235 - culture
Average accuracy 0.100 - law
------------
Average accuracy 0.096 - STEM
Average accuracy 0.146 - humanities
Average accuracy 0.207 - social sciences
Average accuracy 0.220 - other (business, health, misc.)
Average accuracy: 0.166
{'mmlu': 16.56}
mmlu: 16.56
