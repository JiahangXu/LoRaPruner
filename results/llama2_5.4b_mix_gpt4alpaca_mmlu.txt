nohup: ignoring input
prompt_mark 0
{'data_dir': 'data/mmlu', 'ntrain': 5, 'prompt_mark': 0, 'kwargs': {'model_name': 'llmpruner', 'model_path': '../LLM-Pruner/prune_log/llama2_prune_5.4b_mix/pytorch_model.bin', 'tokenizer': 'meta-llama/Llama-2-7b-hf', 'lora_path': '../LLM-Pruner/tune_log/llama2_5.4b_mix_gpt4alpaca'}, 'args': Namespace(data_dir='data/mmlu', ntrain=5, prompt_mark=0, kwargs={'model_name': 'llmpruner', 'model_path': '../LLM-Pruner/prune_log/llama2_prune_5.4b_mix/pytorch_model.bin', 'tokenizer': 'meta-llama/Llama-2-7b-hf', 'lora_path': '../LLM-Pruner/tune_log/llama2_5.4b_mix_gpt4alpaca'}), 'model': LLMPrunerModel(model_path='../LLM-Pruner/prune_log/llama2_prune_5.4b_mix/pytorch_model.bin', max_input_length=2048, max_output_length=2, model=None, tokenizer='meta-llama/Llama-2-7b-hf', lora_path='../LLM-Pruner/tune_log/llama2_5.4b_mix_gpt4alpaca', device='cuda', load_8bit=False, do_sample=False, use_template=False, sys=<module 'sys' (built-in)>)}
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [01:06<1:01:43, 66.14s/it]  4%|▎         | 2/57 [02:09<59:04, 64.44s/it]    5%|▌         | 3/57 [03:41<1:09:24, 77.12s/it]  7%|▋         | 4/57 [04:39<1:01:26, 69.56s/it]  9%|▉         | 5/57 [06:44<1:17:37, 89.57s/it] 11%|█         | 6/57 [07:54<1:10:33, 83.01s/it] 12%|█▏        | 7/57 [08:45<1:00:28, 72.57s/it] 14%|█▍        | 8/57 [09:52<57:42, 70.67s/it]   16%|█▌        | 9/57 [10:44<51:45, 64.70s/it] 18%|█▊        | 10/57 [12:11<56:13, 71.78s/it] 19%|█▉        | 11/57 [13:03<50:14, 65.54s/it] 21%|██        | 12/57 [13:48<44:30, 59.34s/it] 23%|██▎       | 13/57 [15:00<46:24, 63.28s/it] 25%|██▍       | 14/57 [15:42<40:46, 56.90s/it] 26%|██▋       | 15/57 [16:25<36:50, 52.64s/it] 28%|██▊       | 16/57 [18:33<51:21, 75.17s/it] 30%|██▉       | 17/57 [19:18<44:08, 66.21s/it] 32%|███▏      | 18/57 [19:48<36:04, 55.49s/it] 33%|███▎      | 19/57 [21:28<43:34, 68.80s/it] 35%|███▌      | 20/57 [22:33<41:38, 67.53s/it] 37%|███▋      | 21/57 [23:22<37:10, 61.95s/it] 39%|███▊      | 22/57 [25:52<51:33, 88.38s/it] 40%|████      | 23/57 [26:49<44:42, 78.90s/it] 42%|████▏     | 24/57 [27:45<39:37, 72.04s/it] 44%|████▍     | 25/57 [29:34<44:20, 83.16s/it] 46%|████▌     | 26/57 [30:55<42:43, 82.71s/it] 47%|████▋     | 27/57 [32:02<38:59, 77.98s/it] 49%|████▉     | 28/57 [32:51<33:25, 69.16s/it] 51%|█████     | 29/57 [35:39<46:05, 98.75s/it] 53%|█████▎    | 30/57 [37:15<44:02, 97.88s/it] 54%|█████▍    | 31/57 [40:23<54:09, 124.99s/it] 56%|█████▌    | 32/57 [43:18<58:21, 140.05s/it] 58%|█████▊    | 33/57 [44:16<46:08, 115.36s/it] 60%|█████▉    | 34/57 [44:51<35:01, 91.38s/it]  61%|██████▏   | 35/57 [45:36<28:23, 77.41s/it] 63%|██████▎   | 36/57 [46:06<22:05, 63.13s/it] 65%|██████▍   | 37/57 [46:52<19:22, 58.13s/it] 67%|██████▋   | 38/57 [47:33<16:43, 52.82s/it] 68%|██████▊   | 39/57 [47:59<13:30, 45.01s/it] 70%|███████   | 40/57 [49:04<14:26, 50.99s/it] 72%|███████▏  | 41/57 [49:31<11:37, 43.59s/it] 74%|███████▎  | 42/57 [52:49<22:31, 90.11s/it] 75%|███████▌  | 43/57 [54:30<21:47, 93.36s/it] 77%|███████▋  | 44/57 [1:00:18<36:44, 169.56s/it] 79%|███████▉  | 45/57 [1:02:06<30:13, 151.13s/it] 81%|████████  | 46/57 [1:03:28<23:55, 130.46s/it] 82%|████████▏ | 47/57 [1:05:11<20:21, 122.10s/it] 84%|████████▍ | 48/57 [1:07:11<18:13, 121.54s/it] 86%|████████▌ | 49/57 [1:30:20<1:06:53, 501.74s/it] 88%|████████▊ | 50/57 [1:33:13<47:01, 403.09s/it]   89%|████████▉ | 51/57 [1:36:34<34:14, 342.44s/it] 91%|█████████ | 52/57 [1:37:07<20:49, 249.89s/it] 93%|█████████▎| 53/57 [1:39:44<14:47, 221.83s/it] 95%|█████████▍| 54/57 [1:40:40<08:36, 172.27s/it] 96%|█████████▋| 55/57 [1:41:08<04:17, 128.78s/it] 98%|█████████▊| 56/57 [1:41:51<01:43, 103.22s/it]100%|██████████| 57/57 [1:42:29<00:00, 83.62s/it] 100%|██████████| 57/57 [1:42:29<00:00, 107.89s/it]
Average accuracy 0.110 - abstract_algebra
Average accuracy 0.370 - anatomy
Average accuracy 0.164 - astronomy
Average accuracy 0.240 - business_ethics
Average accuracy 0.219 - clinical_knowledge
Average accuracy 0.250 - college_biology
Average accuracy 0.160 - college_chemistry
Average accuracy 0.200 - college_computer_science
Average accuracy 0.170 - college_mathematics
Average accuracy 0.225 - college_medicine
Average accuracy 0.216 - college_physics
Average accuracy 0.260 - computer_security
Average accuracy 0.272 - conceptual_physics
Average accuracy 0.246 - econometrics
Average accuracy 0.283 - electrical_engineering
Average accuracy 0.124 - elementary_mathematics
Average accuracy 0.143 - formal_logic
Average accuracy 0.310 - global_facts
Average accuracy 0.245 - high_school_biology
Average accuracy 0.212 - high_school_chemistry
Average accuracy 0.150 - high_school_computer_science
Average accuracy 0.242 - high_school_european_history
Average accuracy 0.217 - high_school_geography
Average accuracy 0.264 - high_school_government_and_politics
Average accuracy 0.205 - high_school_macroeconomics
Average accuracy 0.056 - high_school_mathematics
Average accuracy 0.202 - high_school_microeconomics
Average accuracy 0.245 - high_school_physics
Average accuracy 0.266 - high_school_psychology
Average accuracy 0.199 - high_school_statistics
Average accuracy 0.309 - high_school_us_history
Average accuracy 0.278 - high_school_world_history
Average accuracy 0.283 - human_aging
Average accuracy 0.237 - human_sexuality
Average accuracy 0.273 - international_law
Average accuracy 0.343 - jurisprudence
Average accuracy 0.276 - logical_fallacies
Average accuracy 0.259 - machine_learning
Average accuracy 0.214 - management
Average accuracy 0.252 - marketing
Average accuracy 0.260 - medical_genetics
Average accuracy 0.273 - miscellaneous
Average accuracy 0.214 - moral_disputes
Average accuracy 0.146 - moral_scenarios
Average accuracy 0.245 - nutrition
Average accuracy 0.289 - philosophy
Average accuracy 0.269 - prehistory
Average accuracy 0.284 - professional_accounting
Average accuracy 0.243 - professional_law
Average accuracy 0.221 - professional_medicine
Average accuracy 0.278 - professional_psychology
Average accuracy 0.255 - public_relations
Average accuracy 0.233 - security_studies
Average accuracy 0.184 - sociology
Average accuracy 0.320 - us_foreign_policy
Average accuracy 0.265 - virology
Average accuracy 0.287 - world_religions
Average accuracy 0.125 - math
Average accuracy 0.253 - health
Average accuracy 0.231 - physics
Average accuracy 0.240 - business
Average accuracy 0.247 - biology
Average accuracy 0.195 - chemistry
Average accuracy 0.218 - computer science
Average accuracy 0.210 - economics
Average accuracy 0.283 - engineering
Average accuracy 0.202 - philosophy
Average accuracy 0.279 - other
Average accuracy 0.275 - history
Average accuracy 0.217 - geography
Average accuracy 0.259 - politics
Average accuracy 0.272 - psychology
Average accuracy 0.205 - culture
Average accuracy 0.251 - law
------------
Average accuracy 0.193 - STEM
Average accuracy 0.235 - humanities
Average accuracy 0.244 - social sciences
Average accuracy 0.261 - other (business, health, misc.)
Average accuracy: 0.234
{'mmlu': 23.38}
mmlu: 23.38
